{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "954c2021-7bea-49dd-acb5-52d217481b3c",
   "metadata": {},
   "source": [
    "# Multi-Agent Resume Tailoring System\n",
    "### Capstone Project - Google & Kaggle AI Agent Intensive Course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9a574f-614e-45f1-a3e1-b488aa0dbef6",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "This project implements a multi-agent system using Google's Agent Development Kit (ADK). The pipeline automates resume tailoring by combining:\n",
    "\n",
    "1. **Resume Intake Agent** â€“ extracts and standardizes resume content  \n",
    "2. **Job Research Agent** â€“ performs live search to identify real job requirements  \n",
    "3. **Resume Rewrite Agent** â€“ merges resume + job insights into a tailored final resume  \n",
    "4. **Polishing Agent** â€“ refines clarity, style, and conciseness\n",
    "\n",
    "## Architecture Diagram\n",
    "\n",
    "## Agent Definitions\n",
    "\n",
    "## Pipeline Design\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "814a5959-ce89-4aff-8a98-98979c082347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gemini API key setup complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "try:\n",
    "    load_dotenv()\n",
    "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "    \n",
    "    print(\"âœ… Gemini API key setup complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"API Authentication Error, please make sure you have setup your .env with the correct GOOGLE_API_KEY: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c8a734-0351-4cf1-b163-ae1cc3f69ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# from google.adk.agents import Agent\n",
    "# from google.adk.runners import InMemoryRunner\n",
    "# from google.adk.tools import google_search\n",
    "# from google.genai import types\n",
    "# from google.adk.agents import LlmAgent\n",
    "# from google.adk.models.google_llm import Gemini\n",
    "# from google.adk.runners import Runner\n",
    "# from google.adk.sessions import InMemorySessionService\n",
    "# from google.adk.memory import InMemoryMemoryService\n",
    "# from google.adk.tools import load_memory, preload_memory\n",
    "# from google.adk.models import Gemini\n",
    "# from google.adk.runners import RunConfig\n",
    "\n",
    "from google.adk.agents import Agent, LlmAgent\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import google_search\n",
    "from google.adk.models import Gemini\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.memory import InMemoryMemoryService\n",
    "import google.generativeai as genai\n",
    "\n",
    "print(\"âœ… ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "aafae2dd-a28d-46ba-a5c1-05935649a558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Logging configured\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# Clean up any previous logs\n",
    "for log_file in [\"logger.log\", \"web.log\", \"tunnel.log\"]:\n",
    "    if os.path.exists(log_file):\n",
    "        os.remove(log_file)\n",
    "        print(f\"ðŸ§¹ Cleaned up {log_file}\")\n",
    "\n",
    "# Configure logging with DEBUG log level.\n",
    "logging.basicConfig(\n",
    "    filename=\"logger.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(filename)s:%(lineno)s %(levelname)s:%(message)s\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Logging configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e79158ed-2a98-42cd-917e-aa992a3aab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic retries to contact the Gemini API if it fails\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e7e68f-276f-4d12-baf8-76573fc86f3f",
   "metadata": {},
   "source": [
    "## Agent Instructions\n",
    "\n",
    "Each agent recieves a different set of instructions tailored to its role. This seperation is key for improving perforance, security, and manageability as we learned in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "19cd7a2f-8f71-4309-8ec6-187985362975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agents + Model created\n"
     ]
    }
   ],
   "source": [
    "INTAKE_INSTRUCTION = (\n",
    "    \"Take the user's raw resume text, do minimal cleaning and extraction (bullet points, skills, structure).\"\n",
    ")\n",
    "\n",
    "JOB_RESEARCH_INSTRUCTION = (\n",
    "    \"Given the job title/company the user enters, perform a Google search and summarize the real skills/qualifications from the job posting.\"\n",
    ")\n",
    "\n",
    "RESUME_REWRITE_INSTRUCTION = (\n",
    "    \"Read the user's resume and the researched job insights. Produce improved, tailored bullet points and targeted edits based on the job description.\"\n",
    ")\n",
    "\n",
    "\n",
    "# Resume Intake Agent\n",
    "resume_intake_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"ResumeIntakeAgent\",\n",
    "    instruction=INTAKE_INSTRUCTION,\n",
    "    tools = [],\n",
    ")\n",
    "logging.info(\"Resume intake agent created\")\n",
    "\n",
    "\n",
    "# Job Research Agent\n",
    "job_research_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"JobResearchAgent\",\n",
    "    instruction=JOB_RESEARCH_INSTRUCTION,\n",
    "    tools = [google_search],\n",
    ")\n",
    "logging.info(\"Job Research agent created\")\n",
    "\n",
    "\n",
    "# # Resume Agent\n",
    "# resume_rewrite_agent = LlmAgent(\n",
    "#     model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "#     name=\"ResumeRewriteAgent\",\n",
    "#     instruction=RESUME_REWRITE_INSTRUCTION,\n",
    "#     tools = [],\n",
    "# )\n",
    "# logging.info(\"Resume Rewriter agent created\")\n",
    "\n",
    "gemini_model = genai.GenerativeModel('gemini-2.5-flash-lite')\n",
    "\n",
    "print(\"âœ… Agents + Model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c11fa2db-2013-418b-8b8c-1a4210f63c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pipeline + helper functions created\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from google.genai import types\n",
    "\n",
    "intake_runner = InMemoryRunner(resume_intake_agent)\n",
    "job_runner = InMemoryRunner(job_research_agent)\n",
    "\n",
    "async def agent_pipeline(resume_text: str, job_query: str):\n",
    "    intake_output = await intake_runner.run_debug(resume_text)\n",
    "    logging.info(\"Intake output generated and saved\")\n",
    "\n",
    "    job_query_output = await job_runner.run_debug(job_query)\n",
    "    logging.info(\"Job query output searched and saved\")\n",
    "\n",
    "\n",
    "    resume_prompt_input = f\"\"\"\n",
    "    You are ResumeRewriteAgent.\n",
    "\n",
    "    Here is the parsed resume:\n",
    "\n",
    "    {intake_output}\n",
    "\n",
    "    Here is the job info for the target role:\n",
    "\n",
    "    {job_query_output}\n",
    "    \n",
    "    Using BOTH, rewrite the resume with tailored bullet points.  Provide the final resume only.\n",
    "    \"\"\"\n",
    "\n",
    "    response = gemini_model.generate_content(resume_prompt_input)\n",
    "\n",
    "    rewrite_output = response.candidates[0].content.parts[0].text\n",
    "\n",
    "    print(\"\\n\\n================== FINAL RESUME ==================\")\n",
    "    print(rewrite_output)\n",
    "\n",
    "    return rewrite_output\n",
    "\n",
    "print(\"âœ… Pipeline + helper functions created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fbb71490-387f-4722-90fb-027e396ca7c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a job (e.g., 'Tesla SWE Intern 2026'):  Rivian Data Science Intern 2026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > \n",
      "ALEX CARTER\n",
      "alex.carter@example.com | (555) 291-8743 | San Diego, CA\n",
      "github.com/alexcarter-dev | linkedin.com/in/alexcarter\n",
      "\n",
      "EDUCATION\n",
      "University of California, San Diego\n",
      "B.S. in Computer Science, Expected June 2026\n",
      "Relevant Coursework: Data Structures & Algorithms, Machine Learning, Operating Systems, Database Systems, Software Engineering\n",
      "\n",
      "TECHNICAL SKILLS\n",
      "Languages: Python, Java, C++, SQL, JavaScript\n",
      "Tools & Frameworks: PyTorch, TensorFlow, React, Node.js, Flask, Docker, Git\n",
      "Concepts: Machine Learning, REST APIs, Distributed Systems, Data Pipelines\n",
      "\n",
      "PROJECTS\n",
      "SmartTransit (Python, ML)\n",
      "â€¢ Built a real-time bus arrival prediction model using LSTM networks, improving prediction accuracy by 18%.\n",
      "â€¢ Designed a pipeline to clean, merge, and process 2M+ GPS datapoints from a public transit dataset.\n",
      "â€¢ Containerised the entire system using Docker to support scalable deployment.\n",
      "\n",
      "PixelForge (React, Node.js)\n",
      "â€¢ Developed a full-stack collaborative drawing platform with real-time canvas syncing over WebSockets.\n",
      "â€¢ Implemented role-based access control and persistent project saving with MongoDB.\n",
      "â€¢ Improved frontend load performance by 30% via code splitting and caching.\n",
      "\n",
      "GPU Weather Simulator (C++, CUDA)\n",
      "â€¢ Accelerated fluid-dynamics-based weather simulation by 12Ã— using CUDA kernels.\n",
      "â€¢ Wrote custom memory-optimised kernels for particle advection and temperature diffusion.\n",
      "\n",
      "WORK EXPERIENCE\n",
      "Software Engineering Intern â€” Horizon Analytics (June 2024 â€“ September 2024)\n",
      "â€¢ Implemented data processing modules for a telemetry monitoring platform ingesting 30K+ events/sec.\n",
      "â€¢ Wrote Python ETL jobs responsible for 15% overall speed improvement.\n",
      "â€¢ Built automated integration tests using pytest and GitHub Actions.\n",
      "\n",
      "LEADERSHIP & ACTIVITIES\n",
      "Computer Science Society â€” Project Team Lead\n",
      "â€¢ Led a 6-student team developing a campus navigation app with indoor routing.\n",
      "â€¢ Managed weekly standups, roadmap planning, and code reviews.\n",
      "\n",
      "Hackathons\n",
      "â€¢ Winner (1st Place), SD Hacks 2024 â€” built a wildfire-risk prediction dashboard using satellite imagery.\n",
      "\n",
      "ADDITIONAL\n",
      "â€¢ Strong interests in ML engineering, distributed systems, and large-scale backend systems.\n",
      "â€¢ Fluent in English and conversational in Spanish.\n",
      "\n",
      "ResumeIntakeAgent > ```json\n",
      "{\n",
      "  \"name\": \"ALEX CARTER\",\n",
      "  \"contact\": {\n",
      "    \"email\": \"alex.carter@example.com\",\n",
      "    \"phone\": \"(555) 291-8743\",\n",
      "    \"location\": \"San Diego, CA\",\n",
      "    \"github\": \"github.com/alexcarter-dev\",\n",
      "    \"linkedin\": \"linkedin.com/in/alexcarter\"\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"institution\": \"University of California, San Diego\",\n",
      "      \"degree\": \"B.S. in Computer Science\",\n",
      "      \"graduation_date\": \"June 2026\",\n",
      "      \"relevant_coursework\": [\n",
      "        \"Data Structures & Algorithms\",\n",
      "        \"Machine Learning\",\n",
      "        \"Operating Systems\",\n",
      "        \"Database Systems\",\n",
      "        \"Software Engineering\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": {\n",
      "    \"languages\": [\n",
      "      \"Python\",\n",
      "      \"Java\",\n",
      "      \"C++\",\n",
      "      \"SQL\",\n",
      "      \"JavaScript\"\n",
      "    ],\n",
      "    \"tools_frameworks\": [\n",
      "      \"PyTorch\",\n",
      "      \"TensorFlow\",\n",
      "      \"React\",\n",
      "      \"Node.js\",\n",
      "      \"Flask\",\n",
      "      \"Docker\",\n",
      "      \"Git\"\n",
      "    ],\n",
      "    \"concepts\": [\n",
      "      \"Machine Learning\",\n",
      "      \"REST APIs\",\n",
      "      \"Distributed Systems\",\n",
      "      \"Data Pipelines\"\n",
      "    ]\n",
      "  },\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"name\": \"SmartTransit\",\n",
      "      \"technologies\": [\n",
      "        \"Python\",\n",
      "        \"ML\"\n",
      "      ],\n",
      "      \"description\": [\n",
      "        \"Built a real-time bus arrival prediction model using LSTM networks, improving prediction accuracy by 18%.\",\n",
      "        \"Designed a pipeline to clean, merge, and process 2M+ GPS datapoints from a public transit dataset.\",\n",
      "        \"Containerised the entire system using Docker to support scalable deployment.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"PixelForge\",\n",
      "      \"technologies\": [\n",
      "        \"React\",\n",
      "        \"Node.js\"\n",
      "      ],\n",
      "      \"description\": [\n",
      "        \"Developed a full-stack collaborative drawing platform with real-time canvas syncing over WebSockets.\",\n",
      "        \"Implemented role-based access control and persistent project saving with MongoDB.\",\n",
      "        \"Improved frontend load performance by 30% via code splitting and caching.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"GPU Weather Simulator\",\n",
      "      \"technologies\": [\n",
      "        \"C++\",\n",
      "        \"CUDA\"\n",
      "      ],\n",
      "      \"description\": [\n",
      "        \"Accelerated fluid-dynamics-based weather simulation by 12Ã— using CUDA kernels.\",\n",
      "        \"Wrote custom memory-optimised kernels for particle advection and temperature diffusion.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"work_experience\": [\n",
      "    {\n",
      "      \"title\": \"Software Engineering Intern\",\n",
      "      \"company\": \"Horizon Analytics\",\n",
      "      \"dates\": \"June 2024 â€“ September 2024\",\n",
      "      \"description\": [\n",
      "        \"Implemented data processing modules for a telemetry monitoring platform ingesting 30K+ events/sec.\",\n",
      "        \"Wrote Python ETL jobs responsible for 15% overall speed improvement.\",\n",
      "        \"Built automated integration tests using pytest and GitHub Actions.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"leadership_activities\": [\n",
      "    {\n",
      "      \"role\": \"Project Team Lead\",\n",
      "      \"organization\": \"Computer Science Society\",\n",
      "      \"description\": [\n",
      "        \"Led a 6-student team developing a campus navigation app with indoor routing.\",\n",
      "        \"Managed weekly standups, roadmap planning, and code reviews.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Winner (1st Place)\",\n",
      "      \"organization\": \"Hackathons\",\n",
      "      \"event\": \"SD Hacks 2024\",\n",
      "      \"description\": [\n",
      "        \"built a wildfire-risk prediction dashboard using satellite imagery.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"additional\": {\n",
      "    \"interests\": [\n",
      "      \"ML engineering\",\n",
      "      \"distributed systems\",\n",
      "      \"large-scale backend systems\"\n",
      "    ],\n",
      "    \"languages\": [\n",
      "      \"Fluent in English\",\n",
      "      \"Conversational in Spanish\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Rivian Data Science Intern 2026\n",
      "JobResearchAgent > For a Data Science Intern position at Rivian in 2026, candidates should be currently pursuing a Bachelor's, Master's, or PhD degree in a related quantitative field. This includes degrees in Data Science, Data Analytics, Data and Machine Learning, Computer Science, Electrical Engineering, Robotics, AI, or Machine Learning.\n",
      "\n",
      "Key skills and qualifications include:\n",
      "*   **Programming Languages:** Proficiency in Python and SQL is essential. Experience with C++, MATLAB, Java, or Kotlin is also mentioned.\n",
      "*   **Data Analysis and Problem-Solving:** Strong analytical and problem-solving skills are required, with the ability to troubleshoot data-related issues.\n",
      "*   **Machine Learning & AI:** A strong understanding of machine learning algorithms and concepts is highly desirable, with previous experience in AI frameworks or machine learning research being a significant plus.\n",
      "*   **Data Handling:** Experience with ETL (Extract, Transform, Load) procedures and SQL-based query construction is preferred.\n",
      "*   **Communication:** Excellent written and verbal communication skills are necessary for collaborating with cross-functional teams and conveying insights.\n",
      "\n",
      "Additionally, candidates are expected to have an expected graduation date between December 2026 and June 2028. This is a \"bucket application,\" meaning your application could be considered for various roles within data science, analytics, and machine learning engineering.\n",
      "================== FINAL RESUME ==================\n",
      "ALEX CARTER\n",
      "San Diego, CA | (555) 291-8743 | alex.carter@example.com | github.com/alexcarter-dev | linkedin.com/in/alexcarter\n",
      "\n",
      "EDUCATION\n",
      "University of California, San Diego | B.S. in Computer Science | June 2026\n",
      "*   Relevant Coursework: Data Structures & Algorithms, Machine Learning, Operating Systems, Database Systems, Software Engineering\n",
      "\n",
      "SKILLS\n",
      "*   **Languages:** Python, SQL, Java, C++, JavaScript\n",
      "*   **Tools & Frameworks:** PyTorch, TensorFlow, React, Node.js, Flask, Docker, Git\n",
      "*   **Concepts:** Machine Learning, REST APIs, Distributed Systems, Data Pipelines, ETL\n",
      "\n",
      "PROJECTS\n",
      "*   **SmartTransit:** Developed a real-time bus arrival prediction model using LSTM networks, improving prediction accuracy by 18%. Designed a data pipeline to process over 2 million GPS data points and containerized the system with Docker for scalable deployment.\n",
      "*   **PixelForge:** Created a full-stack collaborative drawing platform with real-time WebSocket syncing, implementing role-based access control and persistent MongoDB storage. Improved frontend load performance by 30% through code splitting and caching.\n",
      "*   **GPU Weather Simulator:** Accelerated fluid-dynamics-based weather simulation by 12x using custom CUDA kernels, optimizing memory usage for particle advection and temperature diffusion.\n",
      "\n",
      "WORK EXPERIENCE\n",
      "Horizon Analytics | Software Engineering Intern | June 2024 â€“ September 2024\n",
      "*   Implemented data processing modules for a telemetry platform, ingesting over 30,000 events per second.\n",
      "*   Wrote Python ETL jobs that contributed to a 15% overall speed improvement in data processing.\n",
      "*   Developed automated integration tests using pytest and GitHub Actions to ensure code quality.\n",
      "\n",
      "LEADERSHIP ACTIVITIES\n",
      "*   **Project Team Lead:** Computer Science Society | Led a 6-student team in developing a campus navigation app with indoor routing capabilities, managing standups, roadmap planning, and code reviews.\n",
      "*   **Winner (1st Place):** SD Hacks 2024 | Built a wildfire-risk prediction dashboard utilizing satellite imagery.\n",
      "\n",
      "ADDITIONAL\n",
      "*   **Interests:** ML engineering, distributed systems, large-scale backend systems.\n",
      "*   **Languages:** Fluent in English, Conversational in Spanish.\n"
     ]
    }
   ],
   "source": [
    "FAKE_RESUME = \"\"\"\n",
    "ALEX CARTER\n",
    "alex.carter@example.com | (555) 291-8743 | San Diego, CA\n",
    "github.com/alexcarter-dev | linkedin.com/in/alexcarter\n",
    "\n",
    "EDUCATION\n",
    "University of California, San Diego\n",
    "B.S. in Computer Science, Expected June 2026\n",
    "Relevant Coursework: Data Structures & Algorithms, Machine Learning, Operating Systems, Database Systems, Software Engineering\n",
    "\n",
    "TECHNICAL SKILLS\n",
    "Languages: Python, Java, C++, SQL, JavaScript\n",
    "Tools & Frameworks: PyTorch, TensorFlow, React, Node.js, Flask, Docker, Git\n",
    "Concepts: Machine Learning, REST APIs, Distributed Systems, Data Pipelines\n",
    "\n",
    "PROJECTS\n",
    "SmartTransit (Python, ML)\n",
    "â€¢ Built a real-time bus arrival prediction model using LSTM networks, improving prediction accuracy by 18%.\n",
    "â€¢ Designed a pipeline to clean, merge, and process 2M+ GPS datapoints from a public transit dataset.\n",
    "â€¢ Containerised the entire system using Docker to support scalable deployment.\n",
    "\n",
    "PixelForge (React, Node.js)\n",
    "â€¢ Developed a full-stack collaborative drawing platform with real-time canvas syncing over WebSockets.\n",
    "â€¢ Implemented role-based access control and persistent project saving with MongoDB.\n",
    "â€¢ Improved frontend load performance by 30% via code splitting and caching.\n",
    "\n",
    "GPU Weather Simulator (C++, CUDA)\n",
    "â€¢ Accelerated fluid-dynamics-based weather simulation by 12Ã— using CUDA kernels.\n",
    "â€¢ Wrote custom memory-optimised kernels for particle advection and temperature diffusion.\n",
    "\n",
    "WORK EXPERIENCE\n",
    "Software Engineering Intern â€” Horizon Analytics (June 2024 â€“ September 2024)\n",
    "â€¢ Implemented data processing modules for a telemetry monitoring platform ingesting 30K+ events/sec.\n",
    "â€¢ Wrote Python ETL jobs responsible for 15% overall speed improvement.\n",
    "â€¢ Built automated integration tests using pytest and GitHub Actions.\n",
    "\n",
    "LEADERSHIP & ACTIVITIES\n",
    "Computer Science Society â€” Project Team Lead\n",
    "â€¢ Led a 6-student team developing a campus navigation app with indoor routing.\n",
    "â€¢ Managed weekly standups, roadmap planning, and code reviews.\n",
    "\n",
    "Hackathons\n",
    "â€¢ Winner (1st Place), SD Hacks 2024 â€” built a wildfire-risk prediction dashboard using satellite imagery.\n",
    "\n",
    "ADDITIONAL\n",
    "â€¢ Strong interests in ML engineering, distributed systems, and large-scale backend systems.\n",
    "â€¢ Fluent in English and conversational in Spanish.\n",
    "\"\"\"\n",
    "\n",
    "#resume_text = input(\"Paste your resume: \")\n",
    "resume_text = FAKE_RESUME\n",
    "job_query = input(\"Enter a job (e.g., 'Tesla SWE Intern 2026'): \")\n",
    "\n",
    "result = await agent_pipeline(resume_text, job_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "24da871d-a9e3-4c81-bb34-8be3cb40c37d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the cleaned-up resume, followed by an explanation of the improvements:\n",
      "\n",
      "---\n",
      "\n",
      "**ALEX CARTER**\n",
      "San Diego, CA | (555) 291-8743 | alex.carter@example.com | github.com/alexcarter-dev | linkedin.com/in/alexcarter\n",
      "\n",
      "---\n",
      "\n",
      "**EDUCATION**\n",
      "\n",
      "**University of California, San Diego** | San Diego, CA\n",
      "B.S. in Computer Science | Expected June 2026\n",
      "*   Relevant Coursework: Data Structures & Algorithms, Machine Learning, Operating Systems, Database Systems, Software Engineering\n",
      "\n",
      "---\n",
      "\n",
      "**SKILLS**\n",
      "\n",
      "*   **Languages:** Python, SQL, Java, C++, JavaScript\n",
      "*   **Tools & Frameworks:** PyTorch, TensorFlow, React, Node.js, Flask, Docker, Git\n",
      "*   **Concepts:** Machine Learning, REST APIs, Distributed Systems, Data Pipelines, ETL\n",
      "\n",
      "---\n",
      "\n",
      "**PROJECTS**\n",
      "\n",
      "*   **SmartTransit:** Developed a real-time bus arrival prediction model (LSTM) that improved accuracy by 18%. Designed and containerized a data pipeline to process over 2 million GPS data points.\n",
      "*   **PixelForge:** Created a full-stack collaborative drawing platform with real-time WebSocket syncing. Implemented role-based access control and persistent MongoDB storage, improving frontend load performance by 30%.\n",
      "*   **GPU Weather Simulator:** Accelerated fluid-dynamics weather simulation by 12x using custom CUDA kernels, optimizing memory usage for particle advection and temperature diffusion.\n",
      "\n",
      "---\n",
      "\n",
      "**WORK EXPERIENCE**\n",
      "\n",
      "**Horizon Analytics** | San Diego, CA\n",
      "Software Engineering Intern | June 2024 â€“ September 2024\n",
      "*   Implemented data processing modules for a telemetry platform, ingesting over 30,000 events per second.\n",
      "*   Developed Python ETL jobs that accelerated data processing by 15%.\n",
      "*   Created automated integration tests using pytest and GitHub Actions to ensure code quality.\n",
      "\n",
      "---\n",
      "\n",
      "**LEADERSHIP & HONORS**\n",
      "\n",
      "*   **Project Team Lead:** Computer Science Society\n",
      "    *   Led a 6-student team in developing a campus navigation app with indoor routing.\n",
      "    *   Managed standups, roadmap planning, and code reviews.\n",
      "*   **Winner (1st Place):** SD Hacks 2024\n",
      "    *   Developed a wildfire-risk prediction dashboard using satellite imagery.\n",
      "\n",
      "---\n",
      "\n",
      "**ADDITIONAL**\n",
      "\n",
      "*   **Interests:** ML Engineering, Distributed Systems, Large-Scale Backend Systems.\n",
      "*   **Languages:** English (Fluent), Spanish (Conversational).\n",
      "\n",
      "---\n",
      "\n",
      "### Explanation of Improvements:\n",
      "\n",
      "1.  **Conciseness and Simplicity:**\n",
      "    *   **Bullet Points:** Verbs are stronger, and descriptions are tightened to convey the most critical information efficiently. For example, \"Developed a data pipeline to process over 2 million GPS data points and containerized the system with Docker for scalable deployment\" became \"Designed and containerized a data pipeline to process over 2 million GPS data points.\"\n",
      "    *   **Removed Redundancy:** Minor phrasing tweaks to eliminate unnecessary words.\n",
      "\n",
      "2.  **Action-Oriented Language:**\n",
      "    *   All bullet points begin with strong action verbs (e.g., \"Developed,\" \"Implemented,\" \"Created,\" \"Accelerated,\" \"Led\").\n",
      "\n",
      "3.  **Quantifiable Achievements:**\n",
      "    *   Where possible, metrics were retained and highlighted. The improvements made to existing bullets often made the quantification even clearer. For instance, \"improving prediction accuracy by 18%\" is now more direct in the SmartTransit bullet.\n",
      "\n",
      "4.  **Structure and Formatting:**\n",
      "    *   **Contact Information:** Kept clean and at the top.\n",
      "    *   **Education:** Added location for clarity.\n",
      "    *   **Skills:** Maintained clear categorization.\n",
      "    *   **Projects:** Used bold for project titles and streamlined descriptions.\n",
      "    *   **Work Experience:** Added location for the company.\n",
      "    *   **Leadership & Honors:** Consolidated \"Leadership Activities\" and \"Winner\" into a single, more impactful section. Used sub-bullets for clarity under the Project Team Lead role.\n",
      "    *   **Additional:** Renamed to \"Additional\" for a more professional feel, and language proficiency is presented more formally.\n",
      "\n",
      "5.  **Clarity and Readability:**\n",
      "    *   The goal was to make the resume easy to scan and understand, allowing a recruiter or hiring manager to quickly grasp Alex's qualifications and accomplishments.\n",
      "    *   Removed the asterisk from the \"Relevant Coursework\" bullet in Education for a cleaner look.\n",
      "\n",
      "These changes aim to create a polished, professional, and impactful resume that highlights Alex Carter's skills and achievements effectively.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Clean up the following improved resume text. Simplify bullets if needed, make it concise, and produce a polished resume.\n",
    "After the resume, provide a short explanation of what was improved.\n",
    "\n",
    "Resume to clean:\n",
    "{result}\n",
    "\"\"\"\n",
    "\n",
    "response = gemini_model.generate_content(prompt)\n",
    "\n",
    "cleaned_resume_with_explanation = response.candidates[0].content.parts[0].text\n",
    "print(cleaned_resume_with_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3afa88-eb29-4344-8757-0179d0b11bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
