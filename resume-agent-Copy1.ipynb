{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "954c2021-7bea-49dd-acb5-52d217481b3c",
   "metadata": {},
   "source": [
    "# Multi-Agent Resume Tailoring System\n",
    "### Capstone Project - Google & Kaggle AI Agent Intensive Course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9a574f-614e-45f1-a3e1-b488aa0dbef6",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "This project implements a multi-agent system using Google's Agent Development Kit (ADK). The pipeline automates resume tailoring by combining:\n",
    "\n",
    "1. **Resume Intake Agent** â€“ extracts and standardizes resume content  \n",
    "2. **Job Research Agent** â€“ performs live search to identify real job requirements  \n",
    "3. **Resume Rewrite Agent** â€“ merges resume + job insights into a tailored final resume  \n",
    "4. **Polishing Agent** â€“ refines clarity, style, and conciseness\n",
    "\n",
    "## Architecture Diagram\n",
    "\n",
    "## Agent Definitions\n",
    "\n",
    "## Pipeline Design\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "814a5959-ce89-4aff-8a98-98979c082347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gemini API key setup complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "try:\n",
    "    load_dotenv()\n",
    "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "    \n",
    "    print(\"âœ… Gemini API key setup complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"API Authentication Error, please make sure you have setup your .env with the correct GOOGLE_API_KEY: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9c8a734-0351-4cf1-b163-ae1cc3f69ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import Agent, LlmAgent\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import google_search\n",
    "from google.adk.models import Gemini\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.memory import InMemoryMemoryService\n",
    "import google.generativeai as genai\n",
    "\n",
    "print(\"âœ… ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aafae2dd-a28d-46ba-a5c1-05935649a558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Cleaned up logger.log\n",
      "âœ… Logging configured\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# Clean up any previous logs\n",
    "for log_file in [\"logger.log\", \"web.log\", \"tunnel.log\"]:\n",
    "    if os.path.exists(log_file):\n",
    "        os.remove(log_file)\n",
    "        print(f\"ðŸ§¹ Cleaned up {log_file}\")\n",
    "\n",
    "# Configure logging with DEBUG log level.\n",
    "logging.basicConfig(\n",
    "    filename=\"logger.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(filename)s:%(lineno)s %(levelname)s:%(message)s\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Logging configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e79158ed-2a98-42cd-917e-aa992a3aab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic retries to contact the Gemini API if it fails\n",
    "from google.genai import types\n",
    "\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e7e68f-276f-4d12-baf8-76573fc86f3f",
   "metadata": {},
   "source": [
    "## Agent Instructions\n",
    "\n",
    "Each agent recieves a different set of instructions tailored to its role. This seperation is key for improving perforance, security, and manageability as we learned in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19cd7a2f-8f71-4309-8ec6-187985362975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agents instructions created\n"
     ]
    }
   ],
   "source": [
    "INTAKE_INSTRUCTION = \"\"\"\n",
    "    Extract structured resume info (education, skills, projects, experience).\n",
    "    Return bullet points without rewriting or inventing details.\n",
    "\"\"\"\n",
    "\n",
    "JOB_RESEARCH_INSTRUCTION = \"\"\"\n",
    "    Perform a Google search for the given job title/company.\n",
    "    Summarize required skills, preferred qualifications, and responsibilities.\n",
    "\"\"\"\n",
    "\n",
    "REWRITE_INSTRUCTION = \"\"\"\n",
    "    Combine the parsed resume + job research.\n",
    "    Rewrite the resume using strong, tailored bullet points.\n",
    "    Do NOT invent false experience.\n",
    "\"\"\"\n",
    "\n",
    "POLISH_INSTRUCTION = \"\"\"\n",
    "    Clean, format, and simplify the improved resume.\n",
    "    Ensure conciseness, clarity, and consistent style.\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ… Agents instructions created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc9440-eae5-45f9-af95-ea75592f9d24",
   "metadata": {},
   "source": [
    "## Defining Agents and Runners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdf5c8b3-4169-40ed-8241-85a4411024a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agents + Runners created\n"
     ]
    }
   ],
   "source": [
    "resume_intake_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"ResumeIntakeAgent\",\n",
    "    instruction=INTAKE_INSTRUCTION,\n",
    "    tools=[]\n",
    ")\n",
    "\n",
    "job_research_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"JobResearchAgent\",\n",
    "    instruction=JOB_RESEARCH_INSTRUCTION,\n",
    "    tools=[google_search]\n",
    ")\n",
    "\n",
    "resume_rewrite_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"ResumeRewriteAgent\",\n",
    "    instruction=REWRITE_INSTRUCTION,\n",
    "    tools=[]\n",
    ")\n",
    "\n",
    "polish_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"PolishAgent\",\n",
    "    instruction=POLISH_INSTRUCTION,\n",
    "    tools=[]\n",
    ")\n",
    "\n",
    "# Defining Runners\n",
    "intake_runner = InMemoryRunner(resume_intake_agent)\n",
    "job_runner = InMemoryRunner(job_research_agent)\n",
    "rewrite_runner = InMemoryRunner(resume_rewrite_agent)\n",
    "polish_runner = InMemoryRunner(polish_agent)\n",
    "\n",
    "print(\"âœ… Agents + Runners created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55735c0-d8a7-48b9-99f7-8bee9c36f5db",
   "metadata": {},
   "source": [
    "## Multi-Agent Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c11fa2db-2013-418b-8b8c-1a4210f63c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pipeline + helper functions created\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import io\n",
    "\n",
    "async def silent_run_debug(runner, text):\n",
    "    buffer = io.StringIO()\n",
    "    with contextlib.redirect_stdout(buffer):\n",
    "        events = await runner.run_debug(text)\n",
    "\n",
    "    last_text = None\n",
    "\n",
    "    for event in events:\n",
    "        if hasattr(event, \"content\") and event.content:\n",
    "            parts = event.content.parts\n",
    "            if parts and hasattr(parts[0], \"text\"):\n",
    "                last_text = parts[0].text\n",
    "\n",
    "    return last_text\n",
    "\n",
    "async def agent_pipeline(resume_text, job_query):\n",
    "    intake_output = await silent_run_debug(intake_runner, resume_text)\n",
    "    job_output = await silent_run_debug(job_runner, job_query)\n",
    "\n",
    "    resume_prompt = f\"\"\"\n",
    "    Parsed resume:\n",
    "    {intake_output}\n",
    "\n",
    "    Job research:\n",
    "    {job_output}\n",
    "\n",
    "    Rewrite the resume using BOTH.\n",
    "    \"\"\"\n",
    "    rewrite_output = await silent_run_debug(rewrite_runner, resume_prompt)\n",
    "    polish_output = await silent_run_debug(polish_runner, rewrite_output)\n",
    "\n",
    "    return rewrite_output\n",
    "\n",
    "print(\"âœ… Pipeline + helper functions created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8a3df-82f3-4dbb-95fa-aa01a9282836",
   "metadata": {},
   "source": [
    "### Fake Resume Used as Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbb71490-387f-4722-90fb-027e396ca7c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FAKE_RESUME = \"\"\"\n",
    "ALEX CARTER\n",
    "alex.carter@example.com | (555) 291-8743 | San Diego, CA\n",
    "github.com/alexcarter-dev | linkedin.com/in/alexcarter\n",
    "\n",
    "EDUCATION\n",
    "University of California, San Diego\n",
    "B.S. in Computer Science, Expected June 2026\n",
    "Relevant Coursework: Data Structures & Algorithms, Machine Learning, Operating Systems, Database Systems, Software Engineering\n",
    "\n",
    "TECHNICAL SKILLS\n",
    "Languages: Python, Java, C++, SQL, JavaScript\n",
    "Tools & Frameworks: PyTorch, TensorFlow, React, Node.js, Flask, Docker, Git\n",
    "Concepts: Machine Learning, REST APIs, Distributed Systems, Data Pipelines\n",
    "\n",
    "PROJECTS\n",
    "SmartTransit (Python, ML)\n",
    "â€¢ Built a real-time bus arrival prediction model using LSTM networks, improving prediction accuracy by 18%.\n",
    "â€¢ Designed a pipeline to clean, merge, and process 2M+ GPS datapoints from a public transit dataset.\n",
    "â€¢ Containerised the entire system using Docker to support scalable deployment.\n",
    "\n",
    "PixelForge (React, Node.js)\n",
    "â€¢ Developed a full-stack collaborative drawing platform with real-time canvas syncing over WebSockets.\n",
    "â€¢ Implemented role-based access control and persistent project saving with MongoDB.\n",
    "â€¢ Improved frontend load performance by 30% via code splitting and caching.\n",
    "\n",
    "GPU Weather Simulator (C++, CUDA)\n",
    "â€¢ Accelerated fluid-dynamics-based weather simulation by 12Ã— using CUDA kernels.\n",
    "â€¢ Wrote custom memory-optimised kernels for particle advection and temperature diffusion.\n",
    "\n",
    "WORK EXPERIENCE\n",
    "Software Engineering Intern â€” Horizon Analytics (June 2024 â€“ September 2024)\n",
    "â€¢ Implemented data processing modules for a telemetry monitoring platform ingesting 30K+ events/sec.\n",
    "â€¢ Wrote Python ETL jobs responsible for 15% overall speed improvement.\n",
    "â€¢ Built automated integration tests using pytest and GitHub Actions.\n",
    "\n",
    "LEADERSHIP & ACTIVITIES\n",
    "Computer Science Society â€” Project Team Lead\n",
    "â€¢ Led a 6-student team developing a campus navigation app with indoor routing.\n",
    "â€¢ Managed weekly standups, roadmap planning, and code reviews.\n",
    "\n",
    "Hackathons\n",
    "â€¢ Winner (1st Place), SD Hacks 2024 â€” built a wildfire-risk prediction dashboard using satellite imagery.\n",
    "\n",
    "ADDITIONAL\n",
    "â€¢ Strong interests in ML engineering, distributed systems, and large-scale backend systems.\n",
    "â€¢ Fluent in English and conversational in Spanish.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc74cc7-5c1b-48a1-8945-f6e36472e4e9",
   "metadata": {},
   "source": [
    "### Running the Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a8f84bf-48aa-4808-b0b6-5060e7a033d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a job (e.g., 'Tesla SWE Intern 2026'):  Tesla Data Science Intern 2026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== POLISHED RESUME ==================\n",
      "\n",
      " ## Education\n",
      "\n",
      "**University of California, San Diego** â€” B.S. in Computer Science, Expected June 2026\n",
      "*   Relevant Coursework: Data Structures & Algorithms, Machine Learning, Operating Systems, Database Systems, Software Engineering\n",
      "\n",
      "## Technical Skills\n",
      "\n",
      "*   **Languages:** Python, Java, C++, SQL, JavaScript\n",
      "*   **Frameworks & Libraries:** PyTorch, TensorFlow, React, Node.js, Flask, Pandas, NumPy, pytest\n",
      "*   **Tools & Technologies:** Docker, Git, GitHub Actions, MongoDB, CUDA\n",
      "*   **Concepts:** Machine Learning, Deep Learning, Statistical Learning, REST APIs, Distributed Systems, Data Pipelines, Data Analysis, Data Visualization, WebSockets, MLOps\n",
      "\n",
      "## Projects\n",
      "\n",
      "*   **SmartTransit: Real-time Bus Arrival Prediction Model**\n",
      "    *   Developed and deployed a real-time bus arrival prediction model using LSTM networks in Python, achieving an 18% improvement in prediction accuracy.\n",
      "    *   Engineered a comprehensive data pipeline to clean, merge, and process over 2 million GPS data points from a public transit dataset, supporting robust ML model training.\n",
      "    *   Containerized the entire system using Docker, enabling scalable deployment and efficient management of the prediction service.\n",
      "\n",
      "*   **PixelForge: Collaborative Real-time Drawing Platform**\n",
      "    *   Engineered a full-stack collaborative drawing platform using React and Node.js, featuring real-time canvas synchronization over WebSockets.\n",
      "    *   Implemented robust role-based access control and persistent project saving using MongoDB, ensuring secure and reliable data management.\n",
      "    *   Optimized frontend load performance by 30% through strategic implementation of code splitting and caching techniques.\n",
      "\n",
      "*   **GPU-Accelerated Weather Simulation**\n",
      "    *   Significantly accelerated fluid-dynamics-based weather simulations by 12x through the development of custom CUDA kernels in C++.\n",
      "    *   Authored memory-optimized CUDA kernels for particle advection and temperature diffusion, enhancing computational efficiency for complex physical modeling.\n",
      "\n",
      "## Work Experience\n",
      "\n",
      "**Software Engineering Intern** â€” Horizon Analytics (June 2024 â€“ September 2024)\n",
      "*   Implemented critical data processing modules for a high-throughput telemetry monitoring platform, successfully ingesting over 30,000 events per second.\n",
      "*   Developed and optimized Python ETL jobs, resulting in a 15% overall speed improvement in data pipeline execution.\n",
      "*   Built and maintained automated integration tests using pytest and integrated them with GitHub Actions for continuous testing and deployment.\n",
      "\n",
      "## Leadership & Activities\n",
      "\n",
      "**Project Team Lead** â€” Computer Science Society (September 2023 â€“ Present)\n",
      "*   Led a team of 6 students in the development of a campus navigation application, incorporating advanced indoor routing capabilities.\n",
      "*   Managed project execution through weekly stand-up meetings, strategic roadmap planning, and rigorous code reviews to ensure timely delivery and high-quality output.\n",
      "\n",
      "**Hackathon Winner (1st Place)** â€” SD Hacks 2024\n",
      "*   Developed a wildfire-risk prediction dashboard utilizing satellite imagery and machine learning techniques, recognized for its innovative approach and impactful results.\n"
     ]
    }
   ],
   "source": [
    "#resume_text = input(\"Paste your resume: \")\n",
    "resume_text = FAKE_RESUME\n",
    "job_query = input(\"Enter a job (e.g., 'Tesla SWE Intern 2026'): \")\n",
    "\n",
    "result = await agent_pipeline(resume_text, job_query)\n",
    "\n",
    "print(\"\\n\\n================== POLISHED RESUME ==================\\n\\n\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
